{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ancient-american",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from typing import Dict, Tuple, List\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# from evaluation import evaluation\n",
    "import evaluation\n",
    "from model import Distmult, Complex, Conve, Transe\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "interior-invention",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPseudocode - \\n    - Load the poisoned dataset, test.txt is the file with target triples, influential_triples.txt has influential triples\\n    - (but need to load the target triples from target dataset to get correct to_skip_eval; otherwise can regenerate the dicts)\\n    - Load the original model and compute ranks on target triples\\n    - Load the poisoned model and compute ranks on target triples \\n    - Compute the difference in original and poisoned ranks\\n    - Sort the indexes of target triples based on the difference in their ranks\\n    - identify the influential triple for highest rank diff and lowest rank diff\\n'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Pseudocode - \n",
    "    - Load the poisoned dataset, test.txt is the file with target triples, influential_triples.txt has influential triples\n",
    "    - (but need to load the target triples from target dataset to get correct to_skip_eval; otherwise can regenerate the dicts)\n",
    "    - Load the original model and compute ranks on target triples\n",
    "    - Load the poisoned model and compute ranks on target triples \n",
    "    - Compute the difference in original and poisoned ranks\n",
    "    - Sort the indexes of target triples based on the difference in their ranks\n",
    "    - identify the influential triple for highest rank diff and lowest rank diff\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "rural-living",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                            datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                            level = logging.INFO,\n",
    "                            #filename = log_path\n",
    "                           )\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "political-handling",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set arguments to pass to model init later\n",
    "parser = utils.get_argument_parser()\n",
    "sys.argv = ['prog.py']\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "australian-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.model = 'complex'\n",
    "args.original_data = 'FB15k-237'\n",
    "attack_method = 'com_add_3'\n",
    "args.data = '{}_{}_{}_1_1_1'.format(attack_method, args.model, args.original_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "municipal-combat",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set the hyperparams\n",
    "args = utils.set_hyperparams(args)\n",
    "\n",
    "## set the device - legacy code to re-use functions from utils\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "tracked-agriculture",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/06/2022 14:36:09 - INFO - __main__ -   Model name: complex\n",
      "\n",
      "09/06/2022 14:36:09 - INFO - __main__ -   Dataset name: com_add_3_complex_FB15k-237_1_1_1 \n",
      "\n",
      "09/06/2022 14:36:09 - INFO - __main__ -   Original dataset name: FB15k-237 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "logger.info('Model name: {}\\n'.format(args.model))\n",
    "logger.info('Dataset name: {} \\n'.format(args.data))\n",
    "logger.info('Original dataset name: {} \\n'.format(args.original_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "acquired-ticket",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/06/2022 14:36:09 - INFO - __main__ -   ------------ Load the target dataset ----------\n"
     ]
    }
   ],
   "source": [
    "## Load the target dataset and coresponding eval dictionaries\n",
    "logger.info('------------ Load the target dataset ----------')\n",
    "data_path = 'data/target_{}_{}_1'.format(args.model, args.original_data)\n",
    "\n",
    "n_ent, n_rel, ent_to_id, rel_to_id = utils.generate_dicts(data_path)\n",
    "\n",
    "data  = utils.load_data(data_path)\n",
    "train_data, valid_data, test_data = data['train'], data['valid'], data['test']\n",
    "\n",
    "inp_f = open(os.path.join(data_path, 'to_skip_eval.pickle'), 'rb')\n",
    "to_skip_eval: Dict[str, Dict[Tuple[int, int], List[int]]] = pickle.load(inp_f)\n",
    "inp_f.close()\n",
    "to_skip_eval['lhs'] = {(int(k[0]), int(k[1])): v for k,v in to_skip_eval['lhs'].items()}\n",
    "to_skip_eval['rhs'] = {(int(k[0]), int(k[1])): v for k,v in to_skip_eval['rhs'].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "finished-roommate",
   "metadata": {},
   "outputs": [],
   "source": [
    "## example name of original model\n",
    "## FB15k-237_distmult_200_0.5_0.3_0.3.model\n",
    "\n",
    "## example name of poisoned model\n",
    "## sym_add_1_distmult_FB15k-237_1_1_1_distmult_200_0.5_0.3_0.3.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "wooden-offering",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/06/2022 14:36:10 - INFO - __main__ -   -------- Load the original model -----------\n",
      "09/06/2022 14:36:10 - INFO - utils -   Loading saved model from saved_models/FB15k-237_complex_200_0.5_0.3_0.3.model\n",
      "09/06/2022 14:36:10 - INFO - utils -   Key:emb_e_real.weight, Size:torch.Size([14505, 200]), Count:2901000\n",
      "09/06/2022 14:36:10 - INFO - utils -   Key:emb_e_img.weight, Size:torch.Size([14505, 200]), Count:2901000\n",
      "09/06/2022 14:36:10 - INFO - utils -   Key:emb_rel_real.weight, Size:torch.Size([237, 200]), Count:47400\n",
      "09/06/2022 14:36:10 - INFO - utils -   Key:emb_rel_img.weight, Size:torch.Size([237, 200]), Count:47400\n",
      "09/06/2022 14:36:10 - INFO - utils -   Complex(\n",
      "  (emb_e_real): Embedding(14505, 200)\n",
      "  (emb_e_img): Embedding(14505, 200)\n",
      "  (emb_rel_real): Embedding(237, 200)\n",
      "  (emb_rel_img): Embedding(237, 200)\n",
      "  (inp_drop): Dropout(p=0.5, inplace=False)\n",
      "  (loss): BCEWithLogitsLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "logger.info('-------- Load the original model -----------')\n",
    "## set the model path without hyperparam arguments\n",
    "model_dir = 'saved_models/{}_{}_*.model'.format(args.original_data, args.model)\n",
    "for filename in glob.glob(model_dir):\n",
    "    model_path = filename\n",
    "    \n",
    "# add a model and load the pre-trained params\n",
    "original_model = utils.load_model(model_path, args, n_ent, n_rel, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "powered-kenya",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/06/2022 14:36:10 - INFO - __main__ -   ------- Ranks on target dataset from original model ----------\n"
     ]
    }
   ],
   "source": [
    "logger.info('------- Ranks on target dataset from original model ----------')\n",
    "### legacy code\n",
    "if args.add_reciprocals:\n",
    "    num_rel= n_rel\n",
    "else:\n",
    "    num_rel = 0\n",
    "    \n",
    "test_data = torch.from_numpy(test_data.astype('int64')).to(device)\n",
    "ranks_lhs, ranks_rhs = evaluation.get_ranking(original_model, test_data, num_rel, to_skip_eval, device)\n",
    "ranks_lhs, ranks_rhs = np.array(ranks_lhs), np.array(ranks_rhs)\n",
    "ranks = np.mean( np.array([ ranks_lhs, ranks_rhs ]), axis=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "meaning-exhaust",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/06/2022 14:36:13 - INFO - __main__ -   Original mean ranks. Lhs:3.271501272264631, Rhs:2.589821882951654, Mean:2.9306615776081424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mr_lhs = np.mean(ranks_lhs, dtype=np.float64)\n",
    "mr_rhs = np.mean(ranks_rhs, dtype=np.float64)\n",
    "mr = np.mean(ranks, dtype=np.float64)\n",
    "### these should match the mean values from log files\n",
    "logger.info('Original mean ranks. Lhs:{}, Rhs:{}, Mean:{}\\n'.format(mr_lhs, mr_rhs, mr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "differential-diabetes",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/06/2022 14:36:13 - INFO - __main__ -   ------------ Load the poisoned dataset ----------\n"
     ]
    }
   ],
   "source": [
    "## Load the poisoned dataset and coresponding eval dictionaries\n",
    "logger.info('------------ Load the poisoned dataset ----------')\n",
    "data_path = 'data/{}'.format(args.data)\n",
    "\n",
    "n_ent, n_rel, ent_to_id, rel_to_id = utils.generate_dicts(data_path)\n",
    "\n",
    "data  = utils.load_data(data_path)\n",
    "train_data, valid_data, test_data = data['train'], data['valid'], data['test']\n",
    "\n",
    "inp_f = open(os.path.join(data_path, 'to_skip_eval.pickle'), 'rb')\n",
    "to_skip_eval: Dict[str, Dict[Tuple[int, int], List[int]]] = pickle.load(inp_f)\n",
    "inp_f.close()\n",
    "to_skip_eval['lhs'] = {(int(k[0]), int(k[1])): v for k,v in to_skip_eval['lhs'].items()}\n",
    "to_skip_eval['rhs'] = {(int(k[0]), int(k[1])): v for k,v in to_skip_eval['rhs'].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "declared-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all adversarial triples\n",
    "with open(os.path.join(data_path, 'summary_edits.json')) as f:\n",
    "    summary_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "extra-regulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_adv_o = 0\n",
    "num_adv_s = 0\n",
    "for key, value in summary_dict.items():\n",
    "    adv_o, adv_s = value[1], value[2]\n",
    "    if len(adv_o) == 3:\n",
    "        num_adv_o +=1 \n",
    "    if len(adv_s) == 3:\n",
    "        num_adv_s +=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "piano-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### simple check\n",
    "assert(2*test_data.shape[0] == num_adv_o + num_adv_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "engaging-dress",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/06/2022 14:36:14 - INFO - __main__ -   -------- Load the poisoned model -----------\n",
      "09/06/2022 14:36:14 - INFO - utils -   Loading saved model from saved_models/com_add_3_complex_FB15k-237_1_1_1_complex_200_0.5_0.3_0.3.model\n",
      "09/06/2022 14:36:14 - INFO - utils -   Key:emb_e_real.weight, Size:torch.Size([14505, 200]), Count:2901000\n",
      "09/06/2022 14:36:14 - INFO - utils -   Key:emb_e_img.weight, Size:torch.Size([14505, 200]), Count:2901000\n",
      "09/06/2022 14:36:14 - INFO - utils -   Key:emb_rel_real.weight, Size:torch.Size([237, 200]), Count:47400\n",
      "09/06/2022 14:36:14 - INFO - utils -   Key:emb_rel_img.weight, Size:torch.Size([237, 200]), Count:47400\n",
      "09/06/2022 14:36:14 - INFO - utils -   Complex(\n",
      "  (emb_e_real): Embedding(14505, 200)\n",
      "  (emb_e_img): Embedding(14505, 200)\n",
      "  (emb_rel_real): Embedding(237, 200)\n",
      "  (emb_rel_img): Embedding(237, 200)\n",
      "  (inp_drop): Dropout(p=0.5, inplace=False)\n",
      "  (loss): BCEWithLogitsLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "logger.info('-------- Load the poisoned model -----------')\n",
    "## set the model path without hyperparam arguments\n",
    "model_dir = 'saved_models/{}_{}_*.model'.format(args.data, args.model)\n",
    "for filename in glob.glob(model_dir):\n",
    "    model_path = filename\n",
    "    \n",
    "# add a model and load the pre-trained params\n",
    "poisoned_model = utils.load_model(model_path, args, n_ent, n_rel, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "characteristic-worship",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/06/2022 14:36:14 - INFO - __main__ -   ------- Ranks on target dataset from poisoned model ----------\n",
      "09/06/2022 14:36:14 - INFO - __main__ -   (using eval dicts from poisoned data)\n"
     ]
    }
   ],
   "source": [
    "logger.info('------- Ranks on target dataset from poisoned model ----------')\n",
    "logger.info('(using eval dicts from poisoned data)')\n",
    "\n",
    "### legacy code\n",
    "if args.add_reciprocals:\n",
    "    num_rel= n_rel\n",
    "else:\n",
    "    num_rel = 0\n",
    "    \n",
    "test_data = torch.from_numpy(test_data.astype('int64')).to(device)\n",
    "pos_ranks_lhs, pos_ranks_rhs = evaluation.get_ranking(poisoned_model, test_data, num_rel, to_skip_eval, device)\n",
    "pos_ranks_lhs, pos_ranks_rhs = np.array(pos_ranks_lhs), np.array(pos_ranks_rhs)\n",
    "pos_ranks = np.mean( np.array([ pos_ranks_lhs, pos_ranks_rhs ]), axis=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "accepted-nerve",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/06/2022 14:36:17 - INFO - __main__ -   Poisoned mean ranks. Lhs:14.514758269720101, Rhs:6.40941475826972, Mean:10.462086513994912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pos_mr_lhs = np.mean(pos_ranks_lhs, dtype=np.float64)\n",
    "pos_mr_rhs = np.mean(pos_ranks_rhs, dtype=np.float64)\n",
    "pos_mr = np.mean(pos_ranks, dtype=np.float64)\n",
    "### these should match the mean values from log files\n",
    "logger.info('Poisoned mean ranks. Lhs:{}, Rhs:{}, Mean:{}\\n'.format(pos_mr_lhs, pos_mr_rhs, pos_mr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "modified-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks_diff = pos_ranks - ranks\n",
    "sorted_idx = np.argsort(ranks_diff) ## indices of sorted ranks\n",
    "sorted_diffs = ranks_diff[sorted_idx] ## values of sorted ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "proper-hazard",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    if test_data.is_cuda:\n",
    "        test_data = test_data.cpu().numpy() #remove the torch tensor\n",
    "except:\n",
    "    test_data = np.array(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "paperback-jesus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the entities from IDs\n",
    "id_to_ent = {ent_to_id[k]:k for k in ent_to_id.keys()}\n",
    "id_to_rel = {rel_to_id[k]:k for k in rel_to_id.keys()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "subsequent-mercy",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'com_add' in attack_method:\n",
    "    max_s, max_p, max_o = test_data[sorted_idx[-1]]\n",
    "    max_ho, max_ro, max_to = summary_dict[str(sorted_idx[-1])][1]  ## adversarial triple for o-side\n",
    "    max_hod, max_rod, max_tod = summary_dict[str(sorted_idx[-1])][2]\n",
    "    max_hs, max_rs, max_ts = summary_dict[str(sorted_idx[-1])][3]  ## adversarial triple for s-side\n",
    "    max_hsd, max_rsd, max_tsd = summary_dict[str(sorted_idx[-1])][4]\n",
    "\n",
    "    min_s, min_p, min_o = test_data[sorted_idx[0]]\n",
    "    min_ho, min_ro, min_to = summary_dict[str(sorted_idx[0])][1] ## adversarial triple for o-side\n",
    "    min_hod, min_rod, min_tod = summary_dict[str(sorted_idx[0])][2]\n",
    "    min_hs, min_rs, min_ts = summary_dict[str(sorted_idx[0])][3] ## adversarial triple for s-side\n",
    "    min_hsd, min_rsd, min_tsd = summary_dict[str(sorted_idx[0])][4]\n",
    "else:\n",
    "    max_s, max_p, max_o = test_data[sorted_idx[-1]]\n",
    "    max_ho, max_ro, max_to = summary_dict[str(sorted_idx[-1])][1]  ## adversarial triple for o-side\n",
    "    max_hs, max_rs, max_ts = summary_dict[str(sorted_idx[-1])][2]  ## adversarial triple for s-side\n",
    "\n",
    "    min_s, min_p, min_o = test_data[sorted_idx[0]]\n",
    "    min_ho, min_ro, min_to = summary_dict[str(sorted_idx[0])][1] ## adversarial triple for o-side\n",
    "    min_hs, min_rs, min_ts = summary_dict[str(sorted_idx[0])][2] ## adversarial triple for s-side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "exciting-assumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_target = [id_to_ent[max_s], id_to_rel[max_p], id_to_ent[max_o]]\n",
    "max_adv_o = [id_to_ent[max_ho], id_to_rel[max_ro], id_to_ent[max_to]]\n",
    "max_adv_s = [id_to_ent[max_hs], id_to_rel[max_rs], id_to_ent[max_ts]]\n",
    "\n",
    "min_target = [id_to_ent[min_s], id_to_rel[min_p], id_to_ent[min_o]]\n",
    "min_adv_o = [id_to_ent[min_ho], id_to_rel[min_ro], id_to_ent[min_to]]\n",
    "min_adv_s = [id_to_ent[min_hs], id_to_rel[min_rs], id_to_ent[min_ts]]\n",
    "\n",
    "if 'com_add' in attack_method:\n",
    "    max_adv_od = [id_to_ent[max_hod], id_to_rel[max_rod], id_to_ent[max_tod]]\n",
    "    max_adv_sd = [id_to_ent[max_hsd], id_to_rel[max_rsd], id_to_ent[max_tsd]]\n",
    "    \n",
    "    min_adv_od = [id_to_ent[min_hod], id_to_rel[min_rod], id_to_ent[min_tod]]\n",
    "    min_adv_sd = [id_to_ent[min_hsd], id_to_rel[min_rsd], id_to_ent[min_tsd]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "combined-snapshot",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/06/2022 14:36:17 - INFO - __main__ -   ---- For com_add_3 on complex FB15k-237\n",
      "\n",
      "09/06/2022 14:36:17 - INFO - __main__ -   Maximum change in ranks: 2180.5\n",
      "\n",
      "09/06/2022 14:36:17 - INFO - __main__ -   Target triple with maximum change: ['/m/01wv9xn', '/common/topic/webpage./common/webpage/category', '/m/08mbj5d']\n",
      "\n",
      "09/06/2022 14:36:17 - INFO - __main__ -   Corresponding adversarial triple on o-side: ['/m/01wv9xn', '/award/award_winning_work/awards_won./award/award_honor/award_winner', '/m/03rl84']\n",
      "\n",
      "09/06/2022 14:36:17 - INFO - __main__ -   Corresponding adversarial triple on o-side: ['/m/03rl84', '/people/person/spouse_s./people/marriage/location_of_ceremony', '/m/030qb3t']\n",
      "\n",
      "09/06/2022 14:36:17 - INFO - __main__ -   Corresponding adversarial triple on s-side: ['/m/01ckcd', '/award/award_winning_work/awards_won./award/award_honor/award_winner', '/m/0mjn2']\n",
      "\n",
      "09/06/2022 14:36:17 - INFO - __main__ -   Corresponding adversarial triple on s-side: ['/m/0mjn2', '/people/person/spouse_s./people/marriage/location_of_ceremony', '/m/08mbj5d']\n",
      "\n",
      "09/06/2022 14:36:17 - INFO - __main__ -   Minimum change in ranks: -7.0\n",
      "\n",
      "09/06/2022 14:36:17 - INFO - __main__ -   Target triple with minimum change: ['/m/0cqhk0', '/award/award_category/winners./award/award_honor/ceremony', '/m/027hjff']\n",
      "\n",
      "09/06/2022 14:36:17 - INFO - __main__ -   Corresponding adversarial triple on o-side: ['/m/0cqhk0', '/award/award_winning_work/awards_won./award/award_honor/award_winner', '/m/030cx']\n",
      "\n",
      "09/06/2022 14:36:17 - INFO - __main__ -   Corresponding adversarial triple on o-side: ['/m/030cx', '/people/person/spouse_s./people/marriage/location_of_ceremony', '/m/08mbj5d']\n",
      "\n",
      "09/06/2022 14:36:17 - INFO - __main__ -   Corresponding adversarial triple on s-side: ['/m/05lb30', '/award/award_winning_work/awards_won./award/award_honor/award_winner', '/m/07ssc']\n",
      "\n",
      "09/06/2022 14:36:17 - INFO - __main__ -   Corresponding adversarial triple on s-side: ['/m/07ssc', '/people/person/spouse_s./people/marriage/location_of_ceremony', '/m/027hjff']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logger.info('---- For {} on {} {}\\n'.format(attack_method, args.model, args.original_data))\n",
    "\n",
    "logger.info('Maximum change in ranks: {}\\n'.format(sorted_diffs[-1]))\n",
    "logger.info('Target triple with maximum change: {}\\n'.format(max_target))\n",
    "logger.info('Corresponding adversarial triple on o-side: {}\\n'.format(max_adv_o))\n",
    "if 'com_add' in attack_method:\n",
    "    logger.info('Corresponding adversarial triple on o-side: {}\\n'.format(max_adv_od))\n",
    "logger.info('Corresponding adversarial triple on s-side: {}\\n'.format(max_adv_s))\n",
    "if 'com_add' in attack_method:\n",
    "    logger.info('Corresponding adversarial triple on s-side: {}\\n'.format(max_adv_sd))\n",
    "\n",
    "logger.info('Minimum change in ranks: {}\\n'.format(sorted_diffs[0]))\n",
    "logger.info('Target triple with minimum change: {}\\n'.format(min_target))\n",
    "logger.info('Corresponding adversarial triple on o-side: {}\\n'.format(min_adv_o))\n",
    "if 'com_add' in attack_method:\n",
    "    logger.info('Corresponding adversarial triple on o-side: {}\\n'.format(min_adv_od))\n",
    "logger.info('Corresponding adversarial triple on s-side: {}\\n'.format(min_adv_s))\n",
    "if 'com_add' in attack_method:\n",
    "    logger.info('Corresponding adversarial triple on s-side: {}\\n'.format(min_adv_sd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-spouse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "resident-return",
   "metadata": {},
   "source": [
    "use this to change Freebase IDs to values\n",
    "\n",
    "Link - https://freebase.toolforge.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-measurement",
   "metadata": {},
   "source": [
    "Another method is to use the Google Knowledge Graph Search API\n",
    "\n",
    "Link - https://developers.google.com/knowledge-graph/reference/rest/v1/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-attack",
   "metadata": {},
   "source": [
    "Original WN18RR dataset with definition files (to get entity values from IDs) - \n",
    "- Link1 - https://figshare.com/articles/dataset/WN18/11869548/2\n",
    "- Link2 - https://everest.hds.utc.fr/doku.php?id=en:smemlj12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-helping",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-clinic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-scope",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-leeds",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-yahoo",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-composite",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
